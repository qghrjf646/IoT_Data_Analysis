\documentclass[11pt,a4paper]{article}

% Packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[margin=2.5cm]{geometry}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{array}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{xcolor}
\usepackage{fancyhdr}
\usepackage{titlesec}
\usepackage{listings}
\usepackage{enumitem}

% Header/Footer
\pagestyle{fancy}
\fancyhf{}
\rhead{CIC-IIoT-2025 Security Analysis}
\lhead{ML Security}
\rfoot{Page \thepage}

% Hyperref settings
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,
    urlcolor=cyan,
}

% Title
\title{
    \vspace{-1cm}
    \textbf{CIC-IIoT-2025 Cybersecurity Analysis Report}\par\vspace{0.5cm}
    \large Machine Learning for Intrusion Detection in Industrial IoT Networks
}
\author{
    Alexis Le Trung\\
    Yahya Ahachim\\
    Rayan Drissi\\
    Aniss Outaleb\\
    \small ML Security -- EPITA SCIA 2026
}
\date{January 2025}

\begin{document}

\maketitle

\begin{abstract}
This report presents a machine learning-based analysis of the CIC-IIoT-2025 dataset for network intrusion detection in Industrial Internet of Things environments. The study evaluates three unsupervised anomaly detection algorithms and three supervised classification methods, benchmarking their performance using precision, recall, F1-score, AUPRC, balanced accuracy, and Matthews Correlation Coefficient. Additionally, the robustness of models against adversarial perturbations is assessed using the Fast Gradient Sign Method. Results indicate that Local Outlier Factor achieves the best anomaly detection performance (F1=0.831, AUPRC=0.873), Random Forest provides the highest classification accuracy (F1=0.927, AUPRC=0.946), and Random Forest demonstrates the highest adversarial robustness (44.2\% robust accuracy retention).
\end{abstract}

\tableofcontents
\newpage

%==============================================================================
\section{Introduction}
%==============================================================================

\subsection{Background}

The proliferation of Industrial Internet of Things (IIoT) devices has created significant security challenges for critical infrastructure systems. Manufacturing plants, power grids, healthcare facilities, and transportation networks increasingly rely on connected devices, making them attractive targets for cyber attacks. Traditional signature-based intrusion detection systems struggle to detect novel attack patterns, creating a need for machine learning approaches capable of identifying anomalous behavior and classifying known attack types.

The CIC-IIoT-2025 dataset provides a comprehensive collection of network traffic data captured from an IIoT testbed, including realistic attack scenarios representing modern cyber threats. This report analyzes this dataset using both unsupervised and supervised machine learning methods to develop effective intrusion detection capabilities.

\subsection{Objectives}

This study aims to:
\begin{enumerate}
    \item Characterize the CIC-IIoT-2025 dataset and identify discriminative features
    \item Benchmark unsupervised anomaly detection methods (Isolation Forest, One-Class SVM, Local Outlier Factor)
    \item Evaluate supervised classification algorithms (Random Forest, Gradient Boosting, SVM)
    \item Assess model robustness against adversarial attacks using FGSM
    \item Provide recommendations for deploying machine learning-based intrusion detection
\end{enumerate}

\subsection{Methodology}

The analysis follows a systematic approach: data exploration and feature engineering, stratified train/test splitting, hyperparameter tuning via cross-validation, model evaluation using multiple complementary metrics, and adversarial robustness testing using gradient-based attacks.

%==============================================================================
\section{Dataset Description}
%==============================================================================

\subsection{Dataset Overview}

The CIC-IIoT-2025 dataset contains network traffic data captured from an Industrial IoT testbed environment. Table~\ref{tab:dataset_overview} summarizes the dataset characteristics.

\begin{table}[H]
\centering
\caption{Dataset Overview}
\label{tab:dataset_overview}
\begin{tabular}{lr}
\toprule
\textbf{Attribute} & \textbf{Value} \\
\midrule
Total Samples & 227,191 \\
Total Features & 94 \\
Attack Samples & 90,391 (39.79\%) \\
Benign Samples & 136,800 (60.21\%) \\
Attack Categories & 7 \\
Specific Attack Types & 60 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Attack Categories}

The dataset includes seven major attack categories representing diverse threat vectors commonly observed in IIoT environments. Table~\ref{tab:attack_distribution} presents the distribution of attack types.

\begin{table}[H]
\centering
\caption{Attack Category Distribution}
\label{tab:attack_distribution}
\begin{tabular}{lrr}
\toprule
\textbf{Attack Category} & \textbf{Samples} & \textbf{Percentage} \\
\midrule
Reconnaissance & 33,648 & 37.23\% \\
DoS & 18,420 & 20.38\% \\
DDoS & 18,056 & 19.98\% \\
Man-in-the-Middle & 8,062 & 8.92\% \\
Malware & 7,541 & 8.34\% \\
Web Attacks & 2,796 & 3.09\% \\
Brute Force & 1,868 & 2.07\% \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{figures/class_distribution.png}
\caption{Distribution of attack types in the CIC-IIoT-2025 dataset}
\label{fig:class_distribution}
\end{figure}

\subsection{Feature Categories}

The 94 features are organized into several categories:
\begin{itemize}
    \item \textbf{Network Metrics:} Packet counts, byte counts, flow duration
    \item \textbf{TCP Flags:} SYN, ACK, FIN, RST, PSH, URG statistics
    \item \textbf{Protocol Information:} Protocol type distributions
    \item \textbf{Header Information:} IP/TCP header lengths, MSS values
    \item \textbf{Timing Features:} Inter-arrival times, flow duration
\end{itemize}

%==============================================================================
\section{Data Exploration and Preprocessing}
%==============================================================================

\subsection{Feature Correlation Analysis}

Analysis of feature correlations with the attack label revealed the most discriminative features. Table~\ref{tab:top_features} presents the top features ranked by correlation coefficient.

\begin{table}[H]
\centering
\caption{Top Features by Correlation with Attack Label}
\label{tab:top_features}
\begin{tabular}{lr}
\toprule
\textbf{Feature} & \textbf{Correlation} \\
\midrule
network\_mss\_max & 0.5256 \\
network\_mss\_avg & 0.5251 \\
network\_mss\_min & 0.5232 \\
network\_header-length\_min & 0.4635 \\
network\_protocols\_dst\_count & 0.4232 \\
network\_packets\_all\_count & 0.3666 \\
network\_protocols\_src\_count & 0.3632 \\
network\_macs\_all\_count & 0.3619 \\
\bottomrule
\end{tabular}
\end{table}

The correlation analysis reveals that TCP Maximum Segment Size (MSS) features dominate with correlations exceeding 0.52, indicating attack traffic uses non-standard MSS negotiation patterns. Network header length and protocol count features (r=0.36-0.46) form a secondary tier, while packet counts provide additional discriminative power for DoS detection. The dominance of network-layer features suggests detection systems should prioritize packet-level inspection for efficient edge deployment.

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{figures/correlation_heatmap.png}
\caption{Feature correlation heatmap showing relationships between top features}
\label{fig:correlation_heatmap}
\end{figure}

\subsection{Feature Distribution Analysis}

Figure~\ref{fig:feature_distributions} illustrates the distribution of key features across benign and attack traffic classes. Notable differences in distribution patterns provide the basis for machine learning classification.

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{figures/feature_distributions.png}
\caption{Distribution of key features across benign and attack traffic}
\label{fig:feature_distributions}
\end{figure}

The feature distributions show bimodal patterns for MSS features (benign clustering around 1460 bytes, attacks spread wider) and heavy-tailed distributions for packet counts. These characteristics favor tree-based ensemble methods which handle non-linear boundaries and heavy tails without normality assumptions.

\subsection{Data Preprocessing}

The following preprocessing steps were applied:
\begin{enumerate}
    \item \textbf{Missing Value Handling:} NaN values were to be replaced with median, but no NaN values were present in the dataset.
    \item \textbf{Feature Scaling:} StandardScaler normalization for consistent feature ranges
    \item \textbf{Label Encoding:} Binary encoding (0=Benign, 1=Attack) for the target variable
    \item \textbf{Train/Test Split:} 80/20 stratified split preserving class distribution
\end{enumerate}

Final dataset sizes: Training set with 181,752 samples (39.79\% attacks) and test set with 45,439 samples (39.79\% attacks).

%==============================================================================
\section{Anomaly Detection Methods}
%==============================================================================

Anomaly detection methods are essential for detecting zero-day attacks and novel threat patterns that supervised classifiers may miss. Three unsupervised algorithms were evaluated, each trained exclusively on benign traffic.

\subsection{Isolation Forest}

Isolation Forest isolates anomalies by randomly selecting features and split values. Anomalies, being few and different from normal instances, are isolated in fewer splits, resulting in shorter average path lengths in the tree structure.

\textbf{Configuration:} 100 estimators, contamination=0.1, max\_samples='auto', random\_state=42.

\begin{table}[H]
\centering
\caption{Isolation Forest Results}
\label{tab:iforest_results}
\begin{tabular}{lr}
\toprule
\textbf{Metric} & \textbf{Value} \\
\midrule
Precision & 0.8338 \\
Recall & 0.7912 \\
F1-Score & 0.8119 \\
Balanced Accuracy & 0.8435 \\
MCC & 0.6936 \\
AUPRC & 0.8595 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{One-Class SVM}

One-Class SVM learns a decision boundary encompassing the normal data distribution. Points outside this boundary are classified as anomalies.

\textbf{Configuration:} RBF kernel, nu=0.1, gamma='auto'.

\begin{table}[H]
\centering
\caption{One-Class SVM Results}
\label{tab:ocsvm_results}
\begin{tabular}{lr}
\toprule
\textbf{Metric} & \textbf{Value} \\
\midrule
Precision & 0.8286 \\
Recall & 0.7535 \\
F1-Score & 0.7893 \\
Balanced Accuracy & 0.8253 \\
MCC & 0.6626 \\
AUPRC & 0.8257 \\
\bottomrule
\end{tabular}
\end{table}

One-Class SVM exhibits high recall but low precision, indicating excessive false positives where benign traffic is incorrectly classified as attacks.

\subsection{Local Outlier Factor}

Local Outlier Factor (LOF) measures the local density deviation of a data point with respect to its neighbors. Points with significantly lower density than their neighbors are considered outliers.

\textbf{Configuration:} n\_neighbors=20, novelty=True, contamination=0.1.

\begin{table}[H]
\centering
\caption{Local Outlier Factor Results}
\label{tab:lof_results}
\begin{tabular}{lr}
\toprule
\textbf{Metric} & \textbf{Value} \\
\midrule
Precision & 0.8405 \\
Recall & 0.8215 \\
F1-Score & 0.8309 \\
Balanced Accuracy & 0.8592 \\
MCC & 0.7214 \\
AUPRC & 0.8727 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Anomaly Detection Comparison}

\begin{table}[H]
\centering
\caption{Anomaly Detection Methods Comparison}
\label{tab:anomaly_comparison}
\begin{tabular}{lcccccc}
\toprule
\textbf{Model} & \textbf{Precision} & \textbf{Recall} & \textbf{F1} & \textbf{Bal. Acc.} & \textbf{MCC} & \textbf{AUPRC} \\
\midrule
Isolation Forest & 0.8338 & 0.7912 & 0.8119 & 0.8435 & 0.6936 & 0.8595 \\
One-Class SVM & 0.8286 & 0.7535 & 0.7893 & 0.8253 & 0.6626 & 0.8257 \\
\textbf{Local Outlier Factor} & \textbf{0.8405} & \textbf{0.8215} & \textbf{0.8309} & \textbf{0.8592} & \textbf{0.7214} & \textbf{0.8727} \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{figures/anomaly_detection_comparison.png}
\caption{Comparison of anomaly detection methods across all metrics}
\label{fig:anomaly_comparison}
\end{figure}

Local Outlier Factor achieves the best overall performance with the highest F1-score (0.831) and AUPRC (0.873). Isolation Forest provides a strong balance of precision and computational efficiency. One-Class SVM shows improved performance after proper train/test separation, achieving balanced precision (0.829) and recall (0.754).

\subsection{Decision Boundary Characteristics}

Each anomaly detection algorithm creates distinct decision boundaries: Isolation Forest produces axis-aligned rectangular regions effective for single-feature deviations; One-Class SVM learns smooth elliptical boundaries via support vectors; LOF creates adaptive density-based boundaries that handle multi-modal distributions. LOF's local adaptation explains its superior performance on IIoT traffic with multiple operational modes.

%==============================================================================
\section{Classification Methods}
%==============================================================================

Supervised classification methods leverage labeled training data to learn decision boundaries between attack and benign traffic. Three algorithms were evaluated on the full labeled dataset.

\subsection{Random Forest}

Random Forest is an ensemble method that constructs multiple decision trees and aggregates their predictions through majority voting. It provides inherent feature importance ranking and resistance to overfitting.

\textbf{Configuration:} 100 estimators, unlimited depth, min\_samples\_split=2, balanced class weights, random\_state=42.

\begin{table}[H]
\centering
\caption{Random Forest Results}
\label{tab:rf_results}
\begin{tabular}{lr}
\toprule
\textbf{Metric} & \textbf{Value} \\
\midrule
Precision & 0.9953 \\
Recall & 0.8677 \\
F1-Score & 0.9272 \\
Balanced Accuracy & 0.9325 \\
MCC & 0.8895 \\
AUPRC & 0.9459 \\
AUC-ROC & 0.9611 \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{figures/feature_importance_rf.png}
\caption{Top 20 most important features from Random Forest}
\label{fig:feature_importance}
\end{figure}

\subsection{Gradient Boosting}

Gradient Boosting builds trees sequentially, with each tree correcting the errors of the previous ensemble. It typically achieves high accuracy through its iterative refinement process.

\textbf{Configuration:} 100 estimators, learning\_rate=0.1, max\_depth=5, subsample=0.8, random\_state=42.

\begin{table}[H]
\centering
\caption{Gradient Boosting Results}
\label{tab:gb_results}
\begin{tabular}{lr}
\toprule
\textbf{Metric} & \textbf{Value} \\
\midrule
Precision & 0.9919 \\
Recall & 0.8668 \\
F1-Score & 0.9251 \\
Balanced Accuracy & 0.9311 \\
MCC & 0.8861 \\
AUPRC & 0.9451 \\
AUC-ROC & 0.9605 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Support Vector Machine (RBF Kernel)}

Support Vector Machine with RBF kernel maps data to a higher-dimensional space where a linear separator can be found. Due to computational constraints, SVM was trained on a 10,000-sample subset.

\textbf{Configuration:} RBF kernel, C=1.0, gamma='scale', balanced class weights.

\begin{table}[H]
\centering
\caption{SVM (RBF Kernel) Results}
\label{tab:svm_results}
\begin{tabular}{lr}
\toprule
\textbf{Metric} & \textbf{Value} \\
\midrule
Precision & 0.9647 \\
Recall & 0.7983 \\
F1-Score & 0.8736 \\
Balanced Accuracy & 0.8895 \\
MCC & 0.8113 \\
AUPRC & 0.9262 \\
AUC-ROC & 0.9350 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Classification Comparison}

\begin{table}[H]
\centering
\caption{Classification Methods Comparison}
\label{tab:classification_comparison}
\begin{tabular}{lccccccc}
\toprule
\textbf{Model} & \textbf{Prec.} & \textbf{Recall} & \textbf{F1} & \textbf{Bal. Acc.} & \textbf{MCC} & \textbf{AUPRC} & \textbf{AUC} \\
\midrule
\textbf{Random Forest} & \textbf{0.9953} & \textbf{0.8677} & \textbf{0.9272} & \textbf{0.9325} & \textbf{0.8895} & \textbf{0.9459} & \textbf{0.9611} \\
Gradient Boosting & 0.9919 & 0.8668 & 0.9251 & 0.9311 & 0.8861 & 0.9451 & 0.9605 \\
SVM (RBF) & 0.9647 & 0.7983 & 0.8736 & 0.8895 & 0.8113 & 0.9262 & 0.9350 \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{figures/classification_comparison.png}
\caption{Comparison of classification methods across all metrics}
\label{fig:classification_comparison}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{figures/precision_recall_curves.png}
\caption{Precision-recall curves for all classification methods}
\label{fig:pr_curves}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{figures/confusion_matrices.png}
\caption{Confusion matrices for all classification methods}
\label{fig:confusion_matrices}
\end{figure}

Random Forest achieves the best overall performance across most metrics with F1=0.927 and precision above 99.5\%. Gradient Boosting performs comparably (F1=0.925) while providing similar interpretability. All methods achieve precision above 96\%, minimizing false alarms in operational deployment.

\subsection{Decision Boundary Analysis}

Random Forest creates non-linear boundaries via ensemble averaging with natural uncertainty measures from voting margins. Gradient Boosting builds sequential corrections that refine boundaries iteratively, with later trees focusing on difficult cases---explaining its adversarial robustness. SVM finds maximum-margin boundaries but its reliance on support vectors makes it sensitive to adversarial perturbations.

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{figures/decision_boundaries.png}
\caption{Decision boundaries of classification methods projected onto the two most important features.}
\label{fig:classification_decision_boundaries}
\end{figure}

%==============================================================================
\section{Adversarial Machine Learning}
%==============================================================================

\subsection{Background}

Machine learning models for cybersecurity can be vulnerable to adversarial attacks where malicious actors craft inputs designed to evade detection. Understanding model robustness is critical for deployment in security-sensitive applications. This section evaluates model vulnerability using the Fast Gradient Sign Method (FGSM).

\subsection{FGSM Attack Implementation}

The Fast Gradient Sign Method is a white-box attack that uses the gradient of the loss function to create perturbations maximizing classification error. The adversarial example is computed as:

\begin{equation}
x_{adv} = x + \epsilon \cdot \text{sign}(\nabla_x J(\theta, x, y))
\end{equation}

where $x_{adv}$ is the adversarial example, $x$ is the original input, $\epsilon$ is the perturbation magnitude, and $J$ is the loss function with model parameters $\theta$.

\subsection{Attack Results}

Table~\ref{tab:fgsm_results} presents the impact of FGSM attacks on a Linear SVM classifier across different perturbation magnitudes.

\begin{table}[H]
\centering
\caption{FGSM Attack Results on Linear SVM}
\label{tab:fgsm_results}
\begin{tabular}{ccc}
\toprule
\textbf{Epsilon} & \textbf{Robust Accuracy} & \textbf{Attack Success Rate} \\
\midrule
0.01 & 32.10\% & 67.90\% \\
0.05 & 17.71\% & 82.29\% \\
0.10 & 13.28\% & 86.72\% \\
0.20 & 8.18\% & 91.82\% \\
0.50 & 3.14\% & 96.86\% \\
1.00 & 2.04\% & 97.96\% \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{figures/fgsm_attack_analysis.png}
\caption{Impact of FGSM attack strength (epsilon) on model accuracy}
\label{fig:fgsm_analysis}
\end{figure}

\subsection{Model Robustness Comparison}

All models were tested against FGSM attacks with $\epsilon=0.5$ to compare their adversarial robustness. The robust accuracy represents the model's accuracy on adversarial examples, while astute accuracy refers to the original accuracy on clean data.

\begin{table}[H]
\centering
\caption{Adversarial Robustness Comparison ($\epsilon=0.5$)}
\label{tab:robustness_comparison}
\begin{tabular}{lccc}
\toprule
\textbf{Model} & \textbf{Astute Accuracy} & \textbf{Robust Accuracy} & \textbf{Robustness Ratio} \\
\midrule
Linear SVM & 90.24\% & 3.14\% & 3.48\% \\
\textbf{Random Forest} & \textbf{94.55\%} & \textbf{41.81\%} & \textbf{44.22\%} \\
Gradient Boosting & 94.43\% & 34.16\% & 36.18\% \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{figures/model_robustness.png}
\caption{Adversarial robustness comparison across models}
\label{fig:model_robustness}
\end{figure}

\subsection{Robustness Analysis}

The results reveal several important findings:
\begin{itemize}
    \item Linear models are highly vulnerable to gradient-based attacks, with accuracy dropping to 3.14\% under moderate perturbation
    \item Random Forest demonstrates the best robustness (44.22\% retention) due to its ensemble of diverse decision trees
    \item Gradient Boosting also shows strong robustness (36.18\% retention) due to its sequential correction mechanism
    \item All models experience significant accuracy degradation, highlighting the critical need for adversarial defenses in security applications
\end{itemize}

\subsection{Adversarial Visualization}

Figure~\ref{fig:perturbation_vectors} shows how FGSM moves attack samples toward the benign region. As $\epsilon$ increases from 0.1 to 0.5, samples progressively cross the decision boundary, achieving >90\% evasion at $\epsilon=0.5$. Linear SVM is most vulnerable due to uniform gradient direction, while Gradient Boosting's sequential error correction creates multiple defense layers.

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{figures/adversarial_points.png}
\caption{FGSM perturbations moving attack samples toward the benign region.}
\label{fig:perturbation_vectors}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{figures/causative_attack_boundaries.png}
\caption{Impact of causative attacks on decision boundaries.}
\label{fig:vulnerability_comparison}
\end{figure}

%==============================================================================
\section{Results Summary}
%==============================================================================

\subsection{Overall Performance}

\begin{table}[H]
\centering
\caption{Best Models by Task}
\label{tab:best_models}
\begin{tabular}{lll}
\toprule
\textbf{Task} & \textbf{Best Model} & \textbf{Key Metric} \\
\midrule
Zero-day Detection & Local Outlier Factor & F1 = 0.831, AUPRC = 0.873 \\
Attack Classification & Random Forest & F1 = 0.927, AUPRC = 0.946 \\
Adversarial Robustness & Random Forest & 44.22\% robustness ratio \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Metric Selection Guidelines}

\begin{table}[H]
\centering
\caption{Metric Selection Guidelines}
\label{tab:metric_guidelines}
\begin{tabular}{p{3cm}p{5cm}p{5cm}}
\toprule
\textbf{Metric} & \textbf{When to Use} & \textbf{Interpretation} \\
\midrule
Precision & When false alarms are costly & Higher = fewer false positives \\
Recall & When missing attacks is critical & Higher = fewer missed attacks \\
F1-Score & Balanced performance assessment & Harmonic mean of precision/recall \\
AUPRC & Imbalanced datasets & Area under precision-recall curve \\
MCC & Overall quality metric & Balanced measure for binary classification \\
\bottomrule
\end{tabular}
\end{table}

%==============================================================================
\section{Security Implications}
%==============================================================================

\subsection{Attack Pattern Insights}

The analysis reveals several important security observations:
\begin{itemize}
    \item Reconnaissance dominates (37.23\% of attacks), suggesting attackers frequently probe systems before launching targeted attacks
    \item DoS and DDoS attacks account for 40.36\% of attacks combined, highlighting the need for rate limiting and traffic analysis
    \item TCP MSS values are highly discriminative, indicating that attack tools often use non-standard network parameters
    \item Protocol diversity metrics indicate attack complexity and can distinguish between simple and sophisticated threats
\end{itemize}

\subsection{Multi-Layer Defense Strategy}

Based on the evaluation results, a multi-layer defense strategy is recommended:
\begin{enumerate}
    \item \textbf{Layer 1 - Anomaly Detection:} Deploy LOF or Isolation Forest for zero-day attack early warning with low computational overhead
    \item \textbf{Layer 2 - Classification:} Use Random Forest or Gradient Boosting to categorize known attack types with high precision for alert prioritization
    \item \textbf{Layer 3 - Adversarial Defense:} Implement input validation, ensemble voting, and regular model retraining to mitigate adversarial threats
\end{enumerate}

\subsection{Operational Deployment Considerations}

\begin{table}[H]
\centering
\caption{Operational Deployment Recommendations}
\label{tab:deployment}
\begin{tabular}{ll}
\toprule
\textbf{Aspect} & \textbf{Recommendation} \\
\midrule
Model Selection & Random Forest for best robustness \\
Update Frequency & Weekly retraining with new data \\
Threshold Tuning & Adjust based on false alarm tolerance \\
Feature Monitoring & Track feature drift for model degradation \\
Fallback Strategy & Anomaly detection when classifier uncertain \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Defense Strategies}

Key defense approaches include:
\begin{itemize}
    \item \textbf{Input Validation:} Feature range clipping (MSS bounds, timing constraints) and statistical anomaly detection using Mahalanobis distance
    \item \textbf{Adversarial Training:} Augmenting training data with FGSM-generated or Gaussian-noise examples can improve robust accuracy.
    \item \textbf{Ensemble Diversification:} Training models on different feature subsets prevents transferable adversarial examples
    \item \textbf{Detection-Time:} Monitoring prediction confidence and using feature squeezing to identify adversarial inputs
\end{itemize}

%==============================================================================
\section{Conclusions and Future Work}
%==============================================================================

\subsection{Summary of Findings}

This analysis of the CIC-IIoT-2025 dataset demonstrates that machine learning methods can effectively detect and classify cyber attacks in IIoT environments:

\begin{enumerate}
    \item \textbf{Anomaly Detection:} Local Outlier Factor achieves the best balance (F1=0.831, AUPRC=0.873) for detecting unknown attack patterns without requiring labeled attack data
    \item \textbf{Classification:} Random Forest provides the highest accuracy (F1=0.927, MCC=0.889) for categorizing known attacks with very high precision (99.5\%)
    \item \textbf{Adversarial Robustness:} Random Forest demonstrates the best resilience (44.22\% robust accuracy retention) against gradient-based adversarial attacks, followed by Gradient Boosting (36.18\%)
    \item \textbf{Feature Engineering:} Network MSS, protocol counts, and timing features are the most discriminative for distinguishing attack from benign traffic
\end{enumerate}

\subsection{Recommendations}

For immediate deployment:
\begin{itemize}
    \item Deploy Random Forest as the primary detection model for its balance of accuracy and robustness
    \item Implement LOF as a complementary zero-day detection layer
    \item Establish feature monitoring for detecting concept drift and model degradation
\end{itemize}

For enhanced security:
\begin{itemize}
    \item Implement adversarial training to improve model robustness
    \item Develop ensemble voting across multiple models to increase confidence
    \item Create feedback mechanisms for continuous learning from new threats
\end{itemize}

\subsection{Limitations}

\begin{itemize}
    \item The dataset may not capture all emerging attack types and techniques
    \item Feature extraction assumes packet-level network visibility
    \item Adversarial robustness was tested only with FGSM; other attack methods may yield different results
    \item Computational requirements may limit real-time deployment for some algorithms
    \item The analysis focuses on binary classification; multi-class attack categorization requires additional investigation
\end{itemize}

\subsection{Future Work}

Future directions include: evaluating robustness against stronger attacks (PGD, C\&W); incorporating temporal modeling with LSTM/Transformer architectures; developing federated learning for privacy-preserving distributed training; enhancing model explainability; and implementing concept drift detection for evolving attack patterns.

%==============================================================================
\appendix
\section{Complete Metrics Tables}
%==============================================================================

\subsection{Anomaly Detection Results}

\begin{table}[H]
\centering
\caption{Complete Anomaly Detection Results}
\begin{tabular}{lcccccc}
\toprule
\textbf{Model} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Bal. Acc.} & \textbf{MCC} & \textbf{AUPRC} \\
\midrule
Isolation Forest & 0.8338 & 0.7912 & 0.8119 & 0.8435 & 0.6936 & 0.8595 \\
One-Class SVM & 0.8286 & 0.7535 & 0.7893 & 0.8253 & 0.6626 & 0.8257 \\
Local Outlier Factor & 0.8405 & 0.8215 & 0.8309 & 0.8592 & 0.7214 & 0.8727 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Classification Results}

\begin{table}[H]
\centering
\caption{Complete Classification Results}
\begin{tabular}{lccccccc}
\toprule
\textbf{Model} & \textbf{Prec.} & \textbf{Recall} & \textbf{F1} & \textbf{Bal. Acc.} & \textbf{MCC} & \textbf{AUPRC} & \textbf{AUC-ROC} \\
\midrule
Random Forest & 0.9953 & 0.8677 & 0.9272 & 0.9325 & 0.8895 & 0.9459 & 0.9611 \\
Gradient Boosting & 0.9919 & 0.8668 & 0.9251 & 0.9311 & 0.8861 & 0.9451 & 0.9605 \\
SVM (RBF) & 0.9647 & 0.7983 & 0.8736 & 0.8895 & 0.8113 & 0.9262 & 0.9350 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Adversarial Robustness Results}

\begin{table}[H]
\centering
\caption{Complete Adversarial Robustness Results ($\epsilon=0.5$)}
\begin{tabular}{lccc}
\toprule
\textbf{Model} & \textbf{Astute Accuracy} & \textbf{Robust Accuracy} & \textbf{Robustness Ratio} \\
\midrule
Linear SVM & 90.24\% & 3.14\% & 3.48\% \\
Random Forest & 94.55\% & 41.81\% & 44.22\% \\
Gradient Boosting & 94.43\% & 34.16\% & 36.18\% \\
\bottomrule
\end{tabular}
\end{table}

\end{document}
