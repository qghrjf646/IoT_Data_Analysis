\documentclass[aspectratio=169,11pt]{beamer}

% Theme and colors
\usetheme{Madrid}
\usecolortheme{whale}
\setbeamertemplate{navigation symbols}{}
\setbeamertemplate{footline}[frame number]

% Packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{array}
\usepackage{xcolor}

% Custom colors
\definecolor{epita}{RGB}{0,84,147}
\definecolor{darkblue}{RGB}{26,54,93}

\setbeamercolor{title}{fg=white,bg=epita}
\setbeamercolor{frametitle}{fg=white,bg=epita}
\setbeamercolor{structure}{fg=epita}

% Title information
\title{CIC-IIoT-2025 Security Analysis}
\subtitle{Machine Learning for Intrusion Detection in Industrial IoT}
\author{Alexis Le Trung, Yahya Ahachim, Rayan Drissi, Aniss Outaleb}
\institute{ML Security -- EPITA SCIA 2026}
\date{January 2026}

\begin{document}

%==============================================================================
% Slide 1: Title
%==============================================================================
\begin{frame}
\titlepage
\end{frame}

%==============================================================================
% Slide 2: Agenda
%==============================================================================
\begin{frame}{Agenda}
\begin{enumerate}
    \item Dataset Overview and Exploration
    \item Anomaly Detection (Unsupervised)
    \item Classification (Supervised)
    \item Adversarial Machine Learning
    \item Recommendations
\end{enumerate}
\vspace{0.5cm}
\textbf{Objective:} Evaluate ML methods for IIoT intrusion detection and assess adversarial robustness
\end{frame}

%==============================================================================
% Slide 3: Dataset Overview
%==============================================================================
\begin{frame}{CIC-IIoT-2025 Dataset}
\begin{columns}
\begin{column}{0.45\textwidth}
\begin{table}
\centering
\small
\begin{tabular}{lr}
\toprule
\textbf{Attribute} & \textbf{Value} \\
\midrule
Total Samples & 227,191 \\
Features & 94 \\
Attack Samples & 90,391 (39.8\%) \\
Benign Samples & 136,800 (60.2\%) \\
Attack Categories & 7 \\
\bottomrule
\end{tabular}
\end{table}
\vspace{0.3cm}
\small
\textbf{Categories:} Reconnaissance, DoS, DDoS, MitM, Malware, Web, Brute Force
\end{column}
\begin{column}{0.55\textwidth}
\includegraphics[width=\textwidth]{figures/class_distribution.png}
\end{column}
\end{columns}
\end{frame}

%==============================================================================
% Slide 4: Key Features
%==============================================================================
\begin{frame}{Key Discriminative Features}
\begin{columns}
\begin{column}{0.5\textwidth}
\textbf{Top Correlated Features:}
\begin{table}
\centering
\small
\begin{tabular}{lr}
\toprule
\textbf{Feature} & \textbf{Corr.} \\
\midrule
network\_mss\_max & 0.526 \\
network\_mss\_avg & 0.525 \\
network\_header-length\_min & 0.464 \\
network\_protocols\_dst\_count & 0.423 \\
network\_packets\_all\_count & 0.367 \\
\bottomrule
\end{tabular}
\end{table}
\vspace{0.2cm}
\small TCP MSS and protocol diversity are strong attack indicators
\end{column}
\begin{column}{0.5\textwidth}
\includegraphics[width=\textwidth]{figures/correlation_heatmap.png}
\end{column}
\end{columns}
\end{frame}

%==============================================================================
% Slide 5: Anomaly Detection Methods
%==============================================================================
\begin{frame}{Anomaly Detection (Unsupervised)}
\textbf{Trained on benign traffic only} -- Detects zero-day attacks
\vspace{0.3cm}

\begin{table}
\centering
\small
\begin{tabular}{p{3.5cm}p{9cm}}
\toprule
\textbf{Method} & \textbf{Approach} \\
\midrule
Isolation Forest & Tree-based isolation via random partitioning \\
One-Class SVM & Kernel-based boundary in feature space \\
Local Outlier Factor & Local density deviation detection \\
\bottomrule
\end{tabular}
\end{table}
\vspace{0.3cm}
\textbf{Evaluation Metric:} AUPRC (Area Under Precision-Recall Curve) -- robust for imbalanced detection
\end{frame}

%==============================================================================
% Slide 6: Anomaly Detection Results
%==============================================================================
\begin{frame}{Anomaly Detection Results}
\begin{columns}
\begin{column}{0.55\textwidth}
\begin{table}
\centering
\small
\begin{tabular}{lcccc}
\toprule
\textbf{Model} & \textbf{F1} & \textbf{AUPRC} & \textbf{MCC} \\
\midrule
Isolation Forest & 0.812 & 0.860 & 0.694 \\
One-Class SVM & 0.789 & 0.826 & 0.663 \\
\textbf{LOF} & \textbf{0.831} & \textbf{0.873} & \textbf{0.721} \\
\bottomrule
\end{tabular}
\end{table}
\vspace{0.3cm}
\textbf{Winner: Local Outlier Factor}\\
Density-based methods excel on this dataset
\end{column}
\begin{column}{0.45\textwidth}
\includegraphics[width=\textwidth]{figures/anomaly_detection_comparison.png}
\end{column}
\end{columns}
\end{frame}

%==============================================================================
% Slide 7: Classification Methods
%==============================================================================
\begin{frame}{Classification (Supervised)}
\textbf{Using labeled attack and benign samples}
\vspace{0.3cm}

\begin{table}
\centering
\small
\begin{tabular}{p{4cm}p{8.5cm}}
\toprule
\textbf{Method} & \textbf{Approach} \\
\midrule
Random Forest & Ensemble of decision trees with majority voting \\
Gradient Boosting & Sequential boosting with error correction \\
SVM (RBF Kernel) & Kernel-based non-linear separation \\
\bottomrule
\end{tabular}
\end{table}
\vspace{0.3cm}
\textbf{Terminology:}
\begin{itemize}
    \item \textbf{Astute Accuracy:} Performance on clean (non-adversarial) data
    \item \textbf{Robust Accuracy:} Performance under adversarial attack
\end{itemize}
\end{frame}

%==============================================================================
% Slide 8: Classification Results
%==============================================================================
\begin{frame}{Classification Results}
\begin{columns}
\begin{column}{0.55\textwidth}
\begin{table}
\centering
\small
\begin{tabular}{lccc}
\toprule
\textbf{Model} & \textbf{F1} & \textbf{MCC} & \textbf{AUC} \\
\midrule
\textbf{Random Forest} & \textbf{0.927} & \textbf{0.890} & \textbf{0.961} \\
Gradient Boosting & 0.925 & 0.886 & 0.961 \\
SVM (RBF) & 0.874 & 0.811 & 0.935 \\
\bottomrule
\end{tabular}
\end{table}
\vspace{0.3cm}
\textbf{Winner: Random Forest}\\
All classifiers achieve $>$87\% F1-score
\end{column}
\begin{column}{0.45\textwidth}
\includegraphics[width=\textwidth]{figures/classification_comparison.png}
\end{column}
\end{columns}
\end{frame}

%==============================================================================
% Slide 9: Adversarial ML - Exploratory Attack
%==============================================================================
\begin{frame}{Adversarial ML: Exploratory Attack (FGSM)}
\textbf{Fast Gradient Sign Method} -- Perturbs \textit{test-time inputs} to evade detection
\vspace{0.2cm}

\begin{equation*}
x_{adv} = x + \epsilon \cdot \text{sign}(\nabla_x J(\theta, x, y))
\end{equation*}

\begin{columns}
\begin{column}{0.45\textwidth}
\begin{table}
\centering
\small
\begin{tabular}{cc}
\toprule
$\epsilon$ & \textbf{Robust Acc.} \\
\midrule
0.01 & 32.1\% \\
0.05 & 17.7\% \\
0.10 & 13.3\% \\
0.50 & 3.1\% \\
\bottomrule
\end{tabular}
\end{table}
\small \textbf{Model:} Linear SVM (Astute: 90.2\%)\\
\small \textbf{Target:} Test samples only
\end{column}
\begin{column}{0.55\textwidth}
\includegraphics[width=\textwidth]{figures/fgsm_attack_analysis.png}
\end{column}
\end{columns}
\end{frame}

%==============================================================================
% Slide 10: Adversarial ML - Causative Attack
%==============================================================================
\begin{frame}{Adversarial ML: Causative Attack (Data Poisoning)}
\textbf{Label Flipping} -- Poisons \textit{training data} to corrupt learned model
\vspace{0.2cm}

\begin{columns}
\begin{column}{0.5\textwidth}
\textbf{Attack Mechanism:}
\begin{itemize}
    \item Attacker corrupts training labels
    \item Model learns incorrect boundaries
    \item \textit{All} future predictions affected
\end{itemize}
\vspace{0.2cm}
\begin{table}
\centering
\small
\begin{tabular}{cc}
\toprule
\textbf{Poison Rate} & \textbf{Accuracy} \\
\midrule
0\% & 68.8\% \\
10\% & 67.0\% \\
20\% & 63.0\% \\
25\% & 60.5\% \\
\bottomrule
\end{tabular}
\end{table}
\small \textbf{Model:} Linear SVM (2D PCA)\\
\small \textbf{Target:} Training data
\end{column}
\begin{column}{0.5\textwidth}
\includegraphics[width=\textwidth]{figures/causative_attack_boundaries.png}
\vspace{-0.3cm}
\begin{center}
\small Decision boundary shifts as poison rate increases
\end{center}
\end{column}
\end{columns}
\end{frame}

%==============================================================================
% Slide 11: Model Robustness Comparison
%==============================================================================
\begin{frame}{Model Robustness Comparison ($\epsilon=0.5$)}
\begin{table}
\centering
\begin{tabular}{lccc}
\toprule
\textbf{Model} & \textbf{Astute Acc.} & \textbf{Robust Acc.} & \textbf{Robustness Ratio} \\
\midrule
Linear SVM & 90.2\% & 3.1\% & 3.5\% \\
Gradient Boosting & 94.4\% & 34.2\% & 36.2\% \\
\textbf{Random Forest} & \textbf{94.6\%} & \textbf{41.8\%} & \textbf{44.2\%} \\
\bottomrule
\end{tabular}
\end{table}
\vspace{0.5cm}
\begin{center}
\textbf{Finding:} Random Forest retains 44\% accuracy under FGSM attack\\
Linear models collapse to near-random performance
\end{center}
\end{frame}

%==============================================================================
% Slide 12: Summary
%==============================================================================
\begin{frame}{Summary: Best Models by Task}
\begin{table}
\centering
\large
\begin{tabular}{lll}
\toprule
\textbf{Task} & \textbf{Best Model} & \textbf{Key Metric} \\
\midrule
Zero-day Detection & Local Outlier Factor & F1 = 0.831, AUPRC = 0.873 \\
Attack Classification & Random Forest & F1 = 0.927, AUPRC = 0.946 \\
Adversarial Robustness & Random Forest & 44.2\% robust acc. \\
\bottomrule
\end{tabular}
\end{table}
\vspace{0.5cm}
\textbf{Key Insight:} No single model excels at all tasks -- defense-in-depth required
\end{frame}

%==============================================================================
% Slide 13: Recommendations
%==============================================================================
\begin{frame}{Recommendations}
\textbf{Multi-Layer Defense Architecture:}
\vspace{0.3cm}
\begin{enumerate}
    \item \textbf{Layer 1 (LOF):} Zero-day attack early warning
    \item \textbf{Layer 2 (Random Forest):} Classification with best accuracy and adversarial robustness
    \item \textbf{Layer 3:} Input validation and adversarial training
\end{enumerate}
\vspace{0.5cm}
\textbf{Production Hardening:}
\begin{itemize}
    \item Implement adversarial training with augmented samples
    \item Regular model retraining with new threat intelligence
    \item Feature monitoring for distribution drift
\end{itemize}
\end{frame}

%==============================================================================
% Slide 15: Questions
%==============================================================================
\begin{frame}{Questions}
\begin{center}
\vspace{1cm}
{\Large \textbf{Questions?}}
\vspace{1cm}

\textbf{CIC-IIoT-2025 Security Analysis}\\
Machine Learning for Intrusion Detection\\
\vspace{0.5cm}
ML Security -- EPITA SCIA 2026
\end{center}
\end{frame}

\end{document}
